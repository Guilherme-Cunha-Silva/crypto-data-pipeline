![Python](https://img.shields.io/badge/Python-3.x-blue)
![BigQuery](https://img.shields.io/badge/BigQuery-GCP-orange)
![API](https://img.shields.io/badge/API-CoinGecko-green)

# ğŸ“Š Crypto Data Pipeline

**CoinGecko API v3 â†’ Google BigQuery**

Este projeto implementa um pipeline de dados simples, reprodutÃ­vel e
escalÃ¡vel para ingestÃ£o e modelagem de dados de criptomoedas utilizando
a API da CoinGecko (v3) e o Google BigQuery como Data Warehouse.

------------------------------------------------------------------------

## ğŸ¯ Objetivo

Construir um pipeline que:

1.  ğŸ“¥ Coleta um snapshot de mercado via endpoint `/coins/markets`
2.  ğŸ’¾ Persiste o payload bruto em uma tabela RAW no BigQuery
3.  ğŸ† Deriva o Top N ativos por variaÃ§Ã£o de preÃ§o nas Ãºltimas 24h (indicador pode ser variÃ¡vel)	
4.  ğŸ“ˆ Coleta o histÃ³rico diÃ¡rio de preÃ§os via
    `/coins/{id}/market_chart/range`
5.  ğŸ“Š Persiste os dados histÃ³ricos em uma tabela FACT

------------------------------------------------------------------------

## ğŸ—ï¸ Arquitetura do Pipeline

CoinGecko API\
â†“\
Snapshot Markets (/coins/markets)\
â†“\
BigQuery RAW (JSON)\
â†“\
Query Top N por Market Cap\
â†“\
Market Chart Range (/coins/{id}/market_chart/range)\
â†“\
BigQuery FACT (HistÃ³rico DiÃ¡rio)
â†“\
Looker Studio (data viz)

------------------------------------------------------------------------

## ğŸ§° Tecnologias Utilizadas

-   Python 3.x
-   Requests
-   Pandas
-   Google Cloud BigQuery
-   CoinGecko API (Public)

------------------------------------------------------------------------

## âš™ï¸ ConfiguraÃ§Ã£o do Ambiente

### 1ï¸âƒ£ Instalar dependÃªncias (fora do colab)

``` bash
pip install google-cloud-bigquery requests python-dotenv
```

------------------------------------------------------------------------

### 2ï¸âƒ£ VariÃ¡veis de Ambiente

``` bash
export COINGECKO_API_KEY="..."      # Opcional (necessÃ¡rio para PRO)
export COINGECKO_IS_PRO="0"         # "1" para PRO | "0" para Public
export GCP_PROJECT_ID="..."
export BQ_DATASET_ID="..."
```

------------------------------------------------------------------------

## ğŸ”„ Etapas do Pipeline

### ğŸ”¹ 1. Setup

-   ImportaÃ§Ã£o de bibliotecas
-   ConfiguraÃ§Ã£o de variÃ¡veis
-   InicializaÃ§Ã£o do cliente BigQuery

------------------------------------------------------------------------

### ğŸ”¹ 2. FunÃ§Ãµes UtilitÃ¡rias

ImplementaÃ§Ã£o de:

    -   `http_get_json()`
    -   Retry exponencial\
    -   Tratamento de erros HTTP (429, 5xx)\
    -   Controle de rate limit

------------------------------------------------------------------------

### ğŸ”¹ 3. CriaÃ§Ã£o da Tabela RAW

Tabela destinada a armazenar o snapshot bruto da API.

Campos principais:

-   ingestion_timestamp (TIMESTAMP)\
-   source (STRING)\
-   payload (JSON)

------------------------------------------------------------------------

### ğŸ”¹ 4. Coleta do Snapshot de Mercado

Endpoint utilizado:

GET /coins/markets

CaracterÃ­sticas:

-   PaginaÃ§Ã£o controlada\
-   Controle de intervalo entre chamadas\
-   CompatÃ­vel com API Public

------------------------------------------------------------------------

### ğŸ”¹ 5. DerivaÃ§Ã£o do Top N por Market Cap

A partir do Ãºltimo snapshot ingerido na RAW:

-   OrdenaÃ§Ã£o por price_change_percentage_24h_in_currency\
-   SeleÃ§Ã£o dos Top N ativos\
-   PreparaÃ§Ã£o para coleta histÃ³rica

------------------------------------------------------------------------

### ğŸ”¹ 6. Coleta de HistÃ³rico DiÃ¡rio

Endpoint utilizado:

GET /coins/{id}/market_chart/range

Coleta:

-   PreÃ§o\
-   Market Cap\
-   Volume

------------------------------------------------------------------------

### ğŸ”¹ 7. PersistÃªncia na Tabela FACT

Campos tÃ­picos:

-   crypto_id (STRING)\
-   date (DATE)\
-   price (FLOAT)\
-   market_cap (FLOAT)\
-   volume (FLOAT)\

------------------------------------------------------------------------

## ğŸ“ˆ PossÃ­veis EvoluÃ§Ãµes

-   OrquestraÃ§Ã£o com software desejado\
-   Incremental load\
-   Monitoramento e alertas\
-   Camadas RAW â†’ SILVER â†’ GOLD\

------------------------------------------------------------------------

## ğŸš€ Como Executar

1.  Configure as variÃ¡veis de ambiente\
2.  Execute o notebook cÃ©lula a cÃ©lula\
3.  Verifique as tabelas no BigQuery\
4.  Valide os dados ingeridos

------------------------------------------------------------------------

## ğŸ“Œ Resultado Esperado

-   Snapshot bruto versionado na camada RAW\
-   HistÃ³rico estruturado na camada FACT\
-   Base pronta para anÃ¡lises e dashboards
